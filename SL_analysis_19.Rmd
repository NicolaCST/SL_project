```{r}
library(lubridate)
library(rmarkdown)
library(knitr)
library(ggplot2)
library(GGally)
library(class)
library(Hmisc)
library(corrplot)
library(class)
library(randomForest)
library(mda)
library(klaR)
library(dplyr)
library(pROC)

set.seed(42)
```

```{r}
#loading dataset. Dataset need to be in the same folder of the project.
load_dataset = function(data_folder, file){
  PATH = paste(getwd(), data_folder, file, sep="/")
}


##the normalization function is created
nor = function(x) { (x -min(x))/(max(x)-min(x))   }


##this function divides the correct predictions by total number of predictions that tell us how accurate teh model is.
accuracy = function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
precision = function(x){(diag(x)/((rowSums(x)))) * 100}
recall = function(x){(diag(x)/((colSums(x)))) * 100}


#returns two dataset: train and test
get_balanced_dataset = function(data, w_gender=0){
  
  data$tripduration = round(data$tripduration/60,2)
  data$starttime = round(data$starttime/60,2)
  data$stoptime = round(data$stoptime/60,2)
  
  data[c("tripduration", "starttime", "stoptime")] = lapply(data[c("tripduration", "starttime", "stoptime")], nor)
  
  if (w_gender != 0){
    a = subset(data, (age_groups == 1) & gender != 0)
    b = subset(data, (age_groups == 2) & gender != 0)
    c = subset(data, (age_groups == 3) & gender != 0)
    d = subset(data, (age_groups == 4) & gender != 0)
  }else{
    a = subset(data, (age_groups == 1))
    b = subset(data, (age_groups == 2))
    c = subset(data, (age_groups == 3))
    d = subset(data, (age_groups == 4))
  }
    
  
  ##Generate a random number that is 90% of the total number of rows in dataset.
  ran = sample(1:nrow(d), 0.95 * nrow(d)) 
  ##extract training set
  a_s = a[ran,]
  b_s = b[ran,]
  c_s = c[ran,]
  d_s = d[ran,]
  
  a = setdiff(a,a_s)
  b = setdiff(b,b_s)
  c = setdiff(c,c_s)
  d = setdiff(d,d_s)

  ran_test = sample(1:nrow(d), 1 * nrow(d)) 
  
  ##extract testing set
  a_t = a[ran_test,]
  b_t = b[ran_test,]
  c_t = c[ran_test,]
  d_t = d[ran_test,]
  
  data_train = rbind(a_s, b_s, c_s, d_s)
  data_test = rbind(a_t, b_t, c_t, d_t)
  
  rm(a,b,c,d, a_s, b_s, c_s, a_t, b_t, c_t)
  
  return(list(data_train, data_test))
}

# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}


rstudio_viewer <- function(file_name, file_path = NULL) {
    temporary_file <- tempfile()
    dir.create(temporary_file)
    html_file <- file.path(temporary_file, file_name)
    current_path <- ifelse(is.null(file_path),
                           getwd(),
                           path.expand(file_path))
    file.copy(file.path(current_path, file_name), html_file)
    rstudioapi::viewer(html_file)
}

plot_stats <- function(tab, mode="test", cf=F){
  
  cat("\n", "---------", mode, "---------", "\n")
  
  cat("\nAccuracy: ", round(accuracy(tab),2))
  cat("\nPrecision: ", round(precision(tab),2))
  cat("\nRecall: ", round(recall(tab),2), "\n")
  
  if(cf == T){
      cat("\n", "---------", "CF", "---------", "\n")
      tab
  }

}


our_palette = c(rgb(1, 0, 0), 
              rgb(0, 1, 0), 
              rgb(0, 0, 1), 
              rgb(1, 0.5, 0))

```

```{r}
tripdata_2019_r = read.csv(load_dataset("SL_dataset", "tripdata_2019_r.csv"))
```

```{r}
cat("min age:", min(tripdata_2019_r$age))
cat("\nmax age:", max(tripdata_2019_r$age))
cat("\nusers >85y:", nrow(tripdata_2019_r[tripdata_2019_r$age > 85,]))
cat("\nusers <=85:", nrow(tripdata_2019_r[tripdata_2019_r$age <= 85 & tripdata_2019_r$age > 0,]))

par(mfrow=c(1,2))

hist(tripdata_2019_r$age, 
     breaks = 20,
     xlab = "Age",
     main = "Age Histogram 2019")


dens = density(tripdata_2019_r$age)
plot(dens,main = "Age density 2019")
```




```{r}
split_ages = c(16, 30, 45, 65, 85)

data_u85 = tripdata_2019_r[tripdata_2019_r$age <= 85,]
data_u85$age_groups = cut(data_u85$age, breaks=split_ages, include.lowest = TRUE, labels = FALSE)

data_o85 = tripdata_2019_r[tripdata_2019_r$age > 85,]
data_o85$age_groups = 0

data_u85 = subset(data_u85, select = -c(age, birth.year, year))
data_o85 = subset(data_o85, select = -c(age, birth.year, year))
```

```{r}
barplot_age_group = barplot(table(data_u85$age_groups), 
     main = "Age groups count",
     xlab = "Age group",
     ylab = "Freq",
     col = "light Blue")
```
`


```{r}
par(mfrow=c(1,2))


freq_month_19 = barplot(table(data_u85$month), 
     main = "Freq during months",
     xlab = "Months",
     ylab = "Freq",
     col = "light Blue")


mean_dur_19 = c()

for (val in 1:12){
  mean_dur_19[val] =  round(mean(tripdata_2019_r$tripduration[tripdata_2019_r$month == val])/60,2)
}

min_per_month_19 = barplot(mean_dur_19, 
     main = "Avg (min) per month",
     xlab = "Months",
     ylab = "Mins",
     ylim=c(0, max(mean_dur_19) + 5),
     col = "light green",
     names.arg=c("1","2","3","4","5", "6", "7", "8", "9", "10", "11", "12"))
```

EDA on gender and customer type
Remark: Gender, self-reported by member (Zero=unknown; 1=male; 2=female)
```{r}

tab = table(data_u85$gender, data_u85$usertype)
hist = barplot(tab, 
        beside = TRUE, 
        legend = FALSE,
        main = "Gender and UserType",
        xlab = "UserType",
        ylab = "Freq",
        ylim=c(0, max(tab) + 100000),
        names.arg = c("Customer: 0", "Subscriber: 1"),
        col = heat.colors(3))

legend("topleft", legend = c("Unknown", "Male", "Female"),
       fill = heat.colors(3))

text(x = hist, y = tab + 50000, labels = tab, cex = .8)


```


EDA Tripduration vs userType
```{r}
EDA_UT = subset(data_u85, select = c(tripduration, usertype))

customer_dur = EDA_UT[EDA_UT$usertype == 0,]
subscriber_dur = EDA_UT[EDA_UT$usertype == 1,]

den_customer = density(log(customer_dur$tripduration))
den_subscriber = density(log(subscriber_dur$tripduration))

plot(den_customer, main="Customer vs Sub trip duration", col="red")
lines(den_subscriber, col="green")

legend("topright", 
       legend = c("Customer", "Subscriber"),
       fill = c("red", "green"))


# Fill the areas
polygon(den_customer, col = rgb(0.9, 0, 0, alpha = 0.6))
polygon(den_subscriber, col = rgb(0, 0.9, 0, alpha = 0.6))

```


```{r}
c1 = density(data_u85[data_u85$age_groups == 1,]$month, adjust = 3.5)
c2 = density(data_u85[data_u85$age_groups == 2,]$month, adjust = 3.5)
c3 = density(data_u85[data_u85$age_groups == 3,]$month, adjust = 3.5)
c4 = density(data_u85[data_u85$age_groups == 4,]$month, adjust = 3.5)

plot(c1, xlim = c(1,12), main = "Age density over months", col = our_palette[1], lwd = 2)
lines(c2, col = our_palette[2], lwd = 2)
lines(c3, col = our_palette[3], lwd = 2)
lines(c4, col = our_palette[4], lwd = 2)


legend("topleft", 
       legend = c("Group 1: 16-30", "Group 2: 31-45", "Group 3: 46-65", "Group 4: 65+"),
       fill = our_palette)
```
#CORRELATION MATRIX

```{r}
corr_data = subset(data_u85, select = -c(year))
round(var(corr_data),2)
res<-rcorr(as.matrix(corr_data))
a = as.data.frame(flattenCorrMatrix(res$r, res$P))

corrplot(cor(corr_data), type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```
```{r}
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated = findCorrelation(cor(corr_data), cutoff=0.75)
# print indexes of highly correlated attributes
print(highlyCorrelated)
```
```{r}
par(mfrow=c(1,2))
plot(corr_data$start.station.longitude, corr_data$end.station.longitude)
plot(corr_data$start.station.latitude, corr_data$end.station.latitude)

plot(round(corr_data$starttime/3600,2), round(corr_data$stoptime/3600,2))

plot(corr_data$startday, corr_data$stopday)

plot(corr_data$age_groups, corr_data$gender)
```

```{r}
dates <- vector(mode="character", length=nrow(data_u85))

for (i in 1:nrow(data_u85)){
  dates[i] = paste("2019", data_u85$month[i], data_u85$startday[i], sep="-")
}

dates <- weekdays(as.Date(dates))
data_u85$dayname = dates

dates <- vector(mode="character", length=nrow(data_o85))

for (i in 1:nrow(data_o85)){
  dates[i] = paste("2019", data_o85$month[i], data_o85$startday[i], sep="-")
}

dates <- weekdays(as.Date(dates))
data_o85$dayname = dates

data_u85 = subset(data_u85, select = -c(year))
data_o85 = subset(data_o85, select = -c(year))

tab = table(data_u85$dayname)
barplot(tab)
```

###########################################################################################

```{r}
####### BACKW FEATURE SELECTION ###################

full = get_balanced_dataset(corr_data, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))


# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
# run the RFE algorithm
results <- rfe(data_train, as.factor(labels_train), sizes=c(4:15), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
```
  nVar    accuracy    Kappa       AccuracySD    KappaSD
	5	      0.7312    	0.6416	    0.002448    	0.003263	
	10	    0.7562    	0.6750    	0.003129    	0.004171	
	15    	0.7964    	0.7285    	0.003826    	0.005100	




```{r}
####### MULTINOMIAL LOGISTIC REGRESSION ###################

full = get_balanced_dataset(data_u85, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

# Fit the model
multinom_age_model = nnet::multinom(age_groups ~., data = data_train)

pred = predict(multinom_age_model, newdata = data_train)
tab_train = table(pred, data_train$age_groups)

plot_stats(tab_train, mode="train", cf = F)

## TEST SET
pred = predict(multinom_age_model, newdata = data_test)
tab_test = table(pred, data_test$age_groups)

plot_stats(tab_test, cf = T)
```


```{r}
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

#our Y
labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))

##run knn function
knn_model_pred = knn(data_train, data_test, cl=labels_train, k=10)

tab_test_knn = table(knn_model_pred, labels_test)

plot_stats(tab_test_knn, cf = T)

```


```{r}
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

#our Y
labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))

rf_model = randomForest(x = data_train,
                             y = as.factor(labels_train),
                             ntree = 100)



rf_model_pred_train = predict(rf_model, newdata = data_train)
rf_model_pred = predict(rf_model, newdata = data_test)

# train resuls
tab_train_rf = table(rf_model_pred_train, labels_train)
plot_stats(tab_train_rf, mode="train", cf = F)
  
# test result
tab_test_rf = table(rf_model_pred, labels_test)
plot_stats(tab_test_rf, mode="test", cf = T)


# Variable importance plot
varImpPlot(rf_model)

```



```{r}
rocs = multiclass.roc(as.numeric(labels_test), as.numeric(rf_model_pred))
rs = rocs[["rocs"]]
plot.roc(rs[[1]])
sapply(2:length(rs),function(i) lines.roc(rs[[i]],col=i))
```



```{r}
data = subset(data_u85, select = c(age_groups,
                                  start.station.name,
                                  start.station.latitude, 
                                  start.station.longitude,
                                  end.station.name,
                                  end.station.latitude, 
                                  end.station.longitude))

EDA_id_station = subset(data, select = c(start.station.name,
                                         end.station.name,
                                         age_groups))

# TOP 10 START #
tab = as.data.frame(table(EDA_id_station$start.station.name))
top_10_start = tab[order(tab$Freq, decreasing = T),][1:10,]
colnames(top_10_start) = c("start_name", "Freq")

start_tab = data.frame(matrix(NA, nrow = nrow(top_10_start), ncol = 4))
colnames(start_tab) = c("1","2", "3", "4")

for (rowIdx in 1:(nrow(start_tab))) {
  for (colIdx in 1:(ncol(start_tab))) {
    start_tab[rowIdx, colIdx] = nrow(subset(EDA_id_station, age_groups == colIdx & start.station.name == top_10_start[rowIdx,1]))
  }
}

start_tab$start_name = top_10_start$start_name



# TOP 10 END #
end_tab = as.data.frame(table(EDA_id_station$end.station.name))
top_10_end = tab[order(end_tab$Freq, decreasing = T),][1:10,]
colnames(top_10_end) = c("end_name", "Freq")

end_tab = data.frame(matrix(NA, nrow = nrow(top_10_end), ncol = 4))
colnames(end_tab) = c("1","2", "3", "4")

for (rowIdx in 1:(nrow(end_tab))) {
  for (colIdx in 1:(ncol(end_tab))) {
    end_tab[rowIdx, colIdx] = nrow(subset(EDA_id_station, age_groups == colIdx & end.station.name == top_10_end[rowIdx,1]))
  }
}

end_tab$end_name = top_10_end$end_name

```


```{r}
bar = barplot(as.matrix(subset(start_tab, select = -c(start_name))), 
        beside = T,
        cex.names = 1,
        horiz = T,
        las=1,
        main = "TOP-10 Most used start station by age",
        space = c(0,3),
        col = heat.colors(nrow(start_tab)))

legend("topright", legend = start_tab$start_name,
       fill = heat.colors(nrow(start_tab)), cex = 0.8)


bar = barplot(as.matrix(subset(end_tab, select = -c(end_name))), 
        beside = T,
        cex.names = 1,
        horiz = T,
        las=1,
        main = "TOP-10 Most used end station by age",
        space = c(0,3),
        col = heat.colors(nrow(start_tab)))

legend("topright", legend = end_tab$end_name,
       fill = heat.colors(nrow(end_tab)), cex = 0.8)

```


```{r}
tab = table(data$age_groups, data$start.station.name, data$start.station.latitude)
temp = order(colSums(tab), decreasing = TRUE) #da errore 
temp = temp[1:10]

par(mar=c(4,16,4,0))
barplot(temp,
        beside=TRUE,
        col = c("darkgrey", "darkblue", "red", "yellow"),
        las=1,
        cex.axis = 1,
        horiz = TRUE
        )
```


```{r}
temp$start.station.name[1]
```

```{r}
map_start = subset(data_u85, select = c(start.station.name,
                                  start.station.latitude, 
                                  start.station.longitude))
map_start = map_start[!duplicated(map_start[ , c("start.station.name")]),]
map_start = map_start[map_start$start.station.name %in% start_tab$start_name,]


map_end = subset(data_u85, select = c(end.station.name,
                                  end.station.latitude, 
                                  end.station.longitude))
map_end = map_end[!duplicated(map_end[ , c("end.station.name")]),]
map_end = map_end[map_end$end.station.name %in% end_tab$end_name,]



pos_19 = cbind(map_start, 
               end.station.name = map_end$end.station.name,
               end.station.latitude = map_end$end.station.latitude,
               end.station.longitude = map_end$end.station.longitude)

write.csv(pos_19, paste(getwd(), "SL_dataset/2019_pos.csv", sep = "/"), row.names = FALSE)
```


```{python}
import pandas as pd
import numpy as np
import folium
import webbrowser

df_acc = pd.read_csv('C:/Users/Utente/Desktop/SL_project/SL_dataset/2019_pos.csv', dtype=object)

map_hooray = folium.Map(location=[42.361145, -71.057083], zoom_start = 12) 

df_acc['start.station.name'] = df_acc['start.station.name'].astype(str)
df_acc['start.station.latitude'] = df_acc['start.station.latitude'].astype(float)
df_acc['start.station.longitude'] = df_acc['start.station.longitude'].astype(float)


feature_group = folium.FeatureGroup("LocationsStart")
lat = df_acc['start.station.latitude']
lng = df_acc['start.station.longitude']
name = df_acc['start.station.name']

for lt, lg, nm in zip(lat, lng, name):
    feature_group.add_child(folium.Marker(location=[lt,lg],popup=nm,icon=folium.Icon(color="blue")))

map_hooray.add_child(feature_group)

map_hooray.save("BostonMap.html")
```


```{r}
tab = as.data.frame(table(data$age_groups, data$start.station.name))
colnames(tab) = c("age_groups", "start.station.name", "freq")


one = tab[tab$age_groups == 1,]
temp = one[order(one$freq, decreasing = T),][1:10,]

two = tab[tab$age_groups == 2,]
temp = rbind(temp, (two[order(two$freq, decreasing = T),][1:10,]))

three = tab[tab$age_groups == 3,]
temp = rbind(temp, (three[order(three$freq, decreasing = T),][1:10,]))

four = tab[tab$age_groups == 4,]
temp = rbind(temp, (four[order(four$freq, decreasing = T),][1:10,]))

temp$lat = NA
temp$long = NA
temp = as.data.frame(temp)

for (idx in 1:nrow(temp)){
  name = temp$start.station.name[idx]
  
  temp[idx, 4] = data$start.station.latitude[data$start.station.name == name][1]
  temp[idx, 5] = data$start.station.longitude[data$start.station.name == name][1]
}


write.csv(temp, paste(getwd(), "SL_dataset/start_station_by_age_19.csv", sep = "/"), row.names = FALSE)
```


```{python}
df_acc = pd.read_csv('C:/Users/Utente/Desktop/SL_project/SL_dataset/start_station_by_age_19.csv', dtype=object)

df_acc['start.station.name'] = df_acc['start.station.name'].astype(str)
df_acc['age'] = df_acc['age'].astype(int)
df_acc['freq'] = df_acc['freq'].astype(int)
df_acc['lat'] = df_acc['lat'].astype(float)
df_acc['long'] = df_acc['long'].astype(float)


for i in range(1,5):
  map_hooray = folium.Map(location=[42.361145, -71.057083], zoom_start = 12) 
  feature = "LocationsStart_" + str(i)
  
  
  fil = df_acc[df_acc['age'] == i]
  feature_group = folium.FeatureGroup(feature)
  lat = fil['lat']
  lng = fil['long']
  name = fil['start.station.name']
  
  
  for lt, lg, nm in zip(lat, lng, name):
      feature_group.add_child(folium.Marker(location=[lt,lg],popup=nm,icon=folium.Icon(color="blue")))
  
  
  map_hooray.add_child(feature_group)
  map_hooray.save("BostonMap_age" + str(i) + ".html")

```

```{r}
rstudio_viewer("BostonMap_age1.html", getwd())
```


```{r}
data = subset(data_u85, select = -c(#startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    start.station.name,
                                    start.station.latitude, 
                                    start.station.longitude, 
                                    end.station.name,
                                    end.station.latitude, 
                                    end.station.longitude,
                                    dayname))


full = get_balanced_dataset(data, w_gender = 0)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

#our Y
labels_train = data_train$age_groups
labels_test = data_test$age_groups

pr_linear = lda(age_groups~., data = data_train)
prediciton = pr_linear %>% predict(data_test)

##create confusion matrix
tab = table(prediciton$class, labels_test)

cat("Accuracy: ", round(accuracy(tab),2))
cat("\nPrecision: ", round(precision(tab),2))
cat("\nRecall: ", round(recall(tab),2))

pr_linear
```

```{r}
pr_quadratic = qda(age_groups~., data = data_train)
prediciton_quadratic = pr_quadratic %>% predict(data_test)

tab = table(prediciton_quadratic$class, labels_test)

cat("Accuracy: ", round(accuracy(tab),2))
cat("\nPrecision: ", round(precision(tab),2))
cat("\nRecall: ", round(recall(tab),2))
```

```{r}

pr_mixture = mda(age_groups~., data = data_train)
pr_mixture
prediciton_mixture = pr_mixture %>% predict(data_test)

tab = table(prediciton_mixture, labels_test)

cat("Accuracy: ", round(accuracy(tab),2))
cat("\nPrecision: ", round(precision(tab),2))
cat("\nRecall: ", round(recall(tab),2))
```


#ASSUMING GENDER
```{r}
#tripdata_2019_r = read.csv(load_dataset("SL_dataset", "tripdata_2019_r.csv"))
#sub_data = tripdata_2019_r[tripdata_2019_r$age <= 80,]

data = subset(data_u85, select = -c(#startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    start.station.name,
                                    start.station.latitude, 
                                    start.station.longitude, 
                                    end.station.name,
                                    end.station.latitude, 
                                    end.station.longitude
                                    ))



full = get_balanced_dataset(data, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

labels_train = data_train$gender
labels_test = data_test$gender

data_train = subset(data_train, select = -c(gender))
data_test = subset(data_test, select = -c(gender))


classifier_RF = randomForest(x = data_train,
                             y = as.factor(labels_train),
                             ntree = 100)


# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = data_test)
  
# Confusion Matrix
confusion_mtx = table(y_pred, labels_test)
confusion_mtx

# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)

cat("Accuracy: ", round(accuracy(confusion_mtx),2))
cat("\nPrecision: ", round(precision(confusion_mtx),2))
cat("\nRecall: ", round(recall(confusion_mtx),2))
```

```{r}
pred_dataset = subset(data_u85, select = -c(#startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    start.station.name,
                                    start.station.latitude, 
                                    start.station.longitude, 
                                    end.station.name,
                                    end.station.latitude, 
                                    end.station.longitude
                                    ))



pred_dataset = pred_dataset[pred_dataset$gender == 0,]
y_gender = predict(classifier_RF, newdata = pred_dataset[,-9])

pred_dataset$gender = y_gender
table(y_gender)


data_u85$gender[data_u85$gender == 0] = y_gender


tab = table(data_u85$gender, data_u85$usertype)
hist = barplot(tab, 
        beside = TRUE, 
        legend = FALSE,
        main = "Gender and UserType",
        xlab = "UserType",
        ylab = "Freq",
        ylim=c(0, max(tab) + 100000),
        names.arg = c("Customer: 0", "Subscriber: 1"),
        col = heat.colors(2))

legend("topleft", legend = c("Male", "Female"),
       fill = heat.colors(2))

text(x = hist, y = tab + 50000, labels = tab, cex = .8)
```



```{r}
data = subset(data_u80, select = -c(#startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    start.station.name,
                                    start.station.latitude, 
                                    start.station.longitude, 
                                    end.station.name,
                                    end.station.latitude, 
                                    end.station.longitude,
                                    dayname))


full = get_balanced_dataset(data, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

pr_linear =  qda(gender~., data = data_train)
prediciton = pr_linear %>% predict(data_test)

##create confusion matrix
tab = table(prediciton$class, data_test$gender)
tab

cat("Accuracy: ", round(accuracy(tab),2))
cat("\nPrecision: ", round(precision(tab),2))
cat("\nRecall: ", round(recall(tab),2))
```


#AGE PREDICTER
```{r}
data = subset(data_u80, select = -c(year, 
                                    birth.year, 
                                    #startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    #start.station.name,
                                    #start.station.latitude, 
                                    #start.station.longitude, 
                                    #end.station.name,
                                    #end.station.latitude, 
                                    #end.station.longitude,
                                    age,
                                    gender))



full = get_balanced_dataset(data, w_gender = 0)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))


classifier_RF = randomForest(x = data_train,
                             y = as.factor(labels_train),
                             ntree = 100)

# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = data_test)
  
# Confusion Matrix
confusion_mtx = table(y_pred, labels_test)
confusion_mtx

# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)

cat("Accuracy: ", round(accuracy(confusion_mtx),2))
cat("\nPrecision: ", round(precision(confusion_mtx),2))
cat("\nRecall: ", round(recall(confusion_mtx),2))
```

```{r}
pred_dataset_age = data_o85

pred_dataset_age = subset(pred_dataset_age, select = -c(#startday, 
                                                        stopday,
                                                        #end.station.id,  
                                                        #start.station.id, 
                                                        start.station.name,
                                                        #start.station.latitude, 
                                                        #start.station.longitude, 
                                                        end.station.name,
                                                        #end.station.latitude, 
                                                        #end.station.longitude,
                                                        dayname))

y_age_groups = predict(classifier_RF, newdata = pred_dataset_age)

pred_dataset_age$age_groups = y_age_groups
table(y_age_groups)
```

```{r}
full = get_balanced_dataset(data, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))


##run knn function
pr = knn(data_train, data_test, cl=labels_train, k=5)

##create confusion matrix
tab = table(pr, labels_test)


cat("Accuracy: ", round(accuracy(tab),2))
cat("\nPrecision: ", round(precision(tab),2))
cat("\nRecall: ", round(recall(tab),2))

```

#LAST DONE AGE PRED ------------------------------------------------------------------------
```{r}
data = subset(data_u85, select = -c(#startday, 
                                    stopday,
                                    #end.station.id,  
                                    #start.station.id, 
                                    start.station.name,
                                    #start.station.latitude, 
                                    #start.station.longitude, 
                                    end.station.name
                                    #end.station.latitude, 
                                    #end.station.longitude
                                    ))



full = get_balanced_dataset(data, w_gender = 1)
data_train = as.data.frame(full[1])
data_test = as.data.frame(full[2])

labels_train = data_train$age_groups
labels_test = data_test$age_groups

data_train = subset(data_train, select = -c(age_groups))
data_test = subset(data_test, select = -c(age_groups))


classifier_RF = randomForest(x = data_train,
                             y = as.factor(labels_train),
                             ntree = 100)


# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = data_test)
  
# Confusion Matrix
confusion_mtx = table(y_pred, labels_test)
confusion_mtx

cat("Accuracy: ", round(accuracy(confusion_mtx),2))
cat("\nPrecision: ", round(precision(confusion_mtx),2))
cat("\nRecall: ", round(recall(confusion_mtx),2))
```



